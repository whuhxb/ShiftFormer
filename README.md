# ShiftFormer
An Efficient Transformer Beyond Convolution, Self-Attention, and  MLP 
